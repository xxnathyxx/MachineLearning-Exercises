{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61688043",
   "metadata": {},
   "source": [
    "**PROYECTO:** Detección de Spam con Regresión Logística\n",
    "* Mediante el flujo típico en competencias/text classification:\n",
    "1. Cargar y explorar datos\n",
    "2. Preprocesamiento de texto (limpieza, tokenización)\n",
    "3. Representación (TF-IDF)\n",
    "4. División train/test y balanceo de clases\n",
    "5. Entrenamiento con regresión logística\n",
    "6. Evaluación de métricas (accuracy, precisión, recall, F1, matriz de confusión, curva ROC)\n",
    "7. Predicción sobre test y creación de submission.csv\n",
    "\n",
    "Se usará el **dataset clásico SMS Spam Collection** (spam.csv, disponible en Kaggle: SMS Spam Collection Dataset (https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    ").\n",
    "\n",
    "**Objetivo:** \n",
    "Construir un modelo de clasificación binaria para identificar si un mensaje SMS es spam (1) o ham (0).\n",
    "\n",
    "**Dataset:** \n",
    "SMS Spam Collection (columna `label` con valores `spam`/`ham`, columna `message` con el texto)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c665c",
   "metadata": {},
   "source": [
    "# 1) Instalación de librerías (si falta algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95303d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn nltk wordcloud --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7017670",
   "metadata": {},
   "source": [
    "# 2) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea76f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9add033",
   "metadata": {},
   "source": [
    "# 3) Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")[[\"v1\", \"v2\"]]\n",
    "df.columns = [\"label\",\"message\"]\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105dfec1",
   "metadata": {},
   "source": [
    "# 4) Exploración de datos\n",
    "- Revisar balance de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f5e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()\n",
    "sns.countplot(data=df, x=\"label\")\n",
    "plt.title(\"Distribución de clases (spam vs ham)\")\n",
    "plt.show()\n",
    "\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\":0,\"spam\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636bc3e7",
   "metadata": {},
   "source": [
    "# 5) Limpieza de texto\n",
    "- Pasar a minúsculas\n",
    "- Quitar puntuación, números y stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52acca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = \" \".join([w for w in text.split() if w not in stop_words])\n",
    "    return text\n",
    "\n",
    "df[\"clean_msg\"] = df[\"message\"].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506c5c1",
   "metadata": {},
   "source": [
    "# 6) Visualización rápida con WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = \" \".join(df[df[\"label\"]==1][\"clean_msg\"])\n",
    "ham_words = \" \".join(df[df[\"label\"]==0][\"clean_msg\"])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "WordCloud(width=500, height=400, background_color=\"white\").generate(spam_words).to_image().show()\n",
    "plt.title(\"Spam WordCloud\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "WordCloud(width=500, height=400, background_color=\"white\").generate(ham_words).to_image().show()\n",
    "plt.title(\"Ham WordCloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66808b09",
   "metadata": {},
   "source": [
    "# 7) División train/test y vectorización con TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"clean_msg\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "print(\"Shape train TF-IDF:\", X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d762e53",
   "metadata": {},
   "source": [
    "# 8) Modelo de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e4075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_prob = model.predict_proba(X_test_tfidf)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135abd2",
   "metadata": {},
   "source": [
    "# 9) Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
    "\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Ham\",\"Spam\"], yticklabels=[\"Ham\",\"Spam\"])\n",
    "plt.title(\"Matriz de confusión\")\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr, label=\"Logistic Regression (AUC = %.2f)\" % roc_auc_score(y_test, y_prob))\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c20de",
   "metadata": {},
   "source": [
    "# 10) Predicción en nuevos datos (ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c05b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs = [\"Win $5000 now by clicking this link!\", \n",
    "        \"Hi mom, I'll call you after work\"]\n",
    "msgs_clean = [clean_text(m) for m in msgs]\n",
    "msgs_tfidf = tfidf.transform(msgs_clean)\n",
    "preds = model.predict(msgs_tfidf)\n",
    "print(list(zip(msgs, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cdbdae",
   "metadata": {},
   "source": [
    "# 11) Submission estilo Kaggle\n",
    "En competencias de Kaggle se recibe un archivo `test.csv` y se debe crear `submission.csv`.  \n",
    "Aquí lo simulamos: suponiendo que `test.csv` tiene columna `Id` y `message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo simulado\n",
    "fake_test = pd.DataFrame({\n",
    "    \"Id\":[1,2],\n",
    "    \"message\":[\"Claim your free prize!!!\",\"Are we meeting tomorrow?\"]\n",
    "})\n",
    "fake_test[\"clean_msg\"] = fake_test[\"message\"].apply(clean_text)\n",
    "fake_test_tfidf = tfidf.transform(fake_test[\"clean_msg\"])\n",
    "fake_test[\"label\"] = model.predict(fake_test_tfidf)\n",
    "\n",
    "submission = fake_test[[\"Id\",\"label\"]]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8def4cfe",
   "metadata": {},
   "source": [
    "# 12) Ideas para mejorar\n",
    "- Optimizar hiperparámetros de la regresión logística (C, penalty).\n",
    "- Probar representaciones más potentes (Word2Vec, embeddings, transformers).\n",
    "- Usar modelos más avanzados (RandomForest, XGBoost, BERT).\n",
    "- Balancear clases con técnicas como SMOTE si dataset está desbalanceado.\n",
    "- Añadir limpieza más profunda (lematización, stemming)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
